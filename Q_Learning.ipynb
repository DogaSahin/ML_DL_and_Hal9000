{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q_Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWVvQFkXL4gEBG+CfL6sCG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYKUTgo-IKJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811259be-47b0-47c8-c484-07fa05640be9"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install gym\n",
        "\n",
        "import numpy as np\n",
        "import gym\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po7NX7S5KkO0"
      },
      "source": [
        "The goal of this game is to go from the starting state (S) to the goal state (G) by walking only on frozen tiles (F) and avoid holes (H). However, the ice is slippery, so you won't always move in the direction you intend (stochastic environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk-GVLBmIaQl",
        "outputId": "5028cdf7-043b-4d11-8ffd-8131ce4a2e67"
      },
      "source": [
        "env = gym.make(\"FrozenLake-v0\") #selecting an environment\n",
        "\n",
        "action_size = env.action_space.n\n",
        "state_size = env.observation_space.n\n",
        "\n",
        "# Create our Q table (64x4)\n",
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSvkDZVSJa5_"
      },
      "source": [
        "total_episodes = 20000       # Total episodes\n",
        "learning_rate = 0.7          # Learning rate\n",
        "max_steps = 99               # Max steps per episode\n",
        "gamma = 0.95                 # Discounting rate\n",
        "\n",
        "# Exploration parameters\n",
        "epsilon = 1.0                 # Exploration rate\n",
        "max_epsilon = 1.0             # Exploration probability at start\n",
        "min_epsilon = 0.01            # Minimum exploration probability \n",
        "decay_rate = 0.005            # Exponential decay rate for exploration prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqgF_65sJdFS",
        "outputId": "3fab6e71-1267-4da8-d0d3-5ae16f2a6b05"
      },
      "source": [
        "rewards = []\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "      \n",
        "        exp_exp_tradeoff = random.uniform(0, 1)\n",
        "        \n",
        "        if exp_exp_tradeoff > epsilon:\n",
        "            action = np.argmax(qtable[state,:])\n",
        "\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "            \n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # update the table\n",
        "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
        "        \n",
        "        total_rewards += reward\n",
        "        \n",
        "        state = new_state\n",
        "        \n",
        "        #if we're dead : finish episode\n",
        "        if done == True: \n",
        "            break\n",
        "        \n",
        "    # Reduce epsilon (because we need less and less exploration)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
        "    rewards.append(total_rewards)\n",
        "    \n",
        "\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
        "print(qtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 0.4965\n",
            "[[1.52325107e-01 2.63747971e-02 2.41794324e-02 9.16267454e-02]\n",
            " [8.83244265e-03 4.26863631e-04 4.17398217e-03 7.90928077e-02]\n",
            " [7.26867495e-03 1.05946802e-02 1.22299848e-02 3.98676648e-02]\n",
            " [4.46339989e-03 3.10979017e-03 4.29980150e-03 3.10512658e-02]\n",
            " [2.29772571e-01 1.79279259e-02 8.10617061e-03 1.65250650e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.77113437e-04 2.43558141e-04 6.23321404e-02 4.16837622e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.51027527e-02 1.75680346e-01 5.46257610e-02 4.91842297e-01]\n",
            " [8.28924645e-03 6.96406732e-01 1.50638216e-02 7.70968664e-03]\n",
            " [5.44523671e-01 3.40919657e-03 3.47419719e-02 3.47792479e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.84523242e-01 6.75633205e-02 7.42142532e-01 6.50774891e-02]\n",
            " [1.10953258e-01 9.24253552e-01 2.86890502e-01 2.31024235e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIMUF-agJoW8",
        "outputId": "4e1c330e-0c20-46b0-f329-ee4ba4e74452"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "for episode in range(5):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "    print(\"EPISODE \", episode)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "      \n",
        "        action = np.argmax(qtable[state,:])        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            env.render()\n",
        "            if new_state == 15:\n",
        "                print(\"WE ARE THE CHAMPIONS\")\n",
        "            else:\n",
        "                print(\"FATALITY\")\n",
        "            \n",
        "            print(\"Number of steps\", step)\n",
        "            \n",
        "            break\n",
        "        state = new_state\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------\n",
            "EPISODE  0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 11\n",
            "--------------------------------------------------------------\n",
            "EPISODE  1\n",
            "  (Right)\n",
            "SFFF\n",
            "FHF\u001b[41mH\u001b[0m\n",
            "FFFH\n",
            "HFFG\n",
            "FATALITY\n",
            "Number of steps 50\n",
            "--------------------------------------------------------------\n",
            "EPISODE  2\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 20\n",
            "--------------------------------------------------------------\n",
            "EPISODE  3\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 56\n",
            "--------------------------------------------------------------\n",
            "EPISODE  4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-MJUvC3TRmD"
      },
      "source": [
        "Trying algortihm with a different learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh9_NJt2R1Wc"
      },
      "source": [
        "total_episodes = 20000        # Total episodes\n",
        "learning_rate = 0.5           # Learning rate\n",
        "max_steps = 99                # Max steps per episode\n",
        "gamma = 0.95                  # Discounting rate\n",
        "\n",
        "# Exploration parameters\n",
        "epsilon = 1.0                 # Exploration rate\n",
        "max_epsilon = 1.0             # Exploration probability at start\n",
        "min_epsilon = 0.01            # Minimum exploration probability \n",
        "decay_rate = 0.005            # Exponential decay rate for exploration prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVtkqLSWSAQH",
        "outputId": "2b883bad-96e0-494b-b4ac-de1103a4395a"
      },
      "source": [
        "rewards = []\n",
        "\n",
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "      \n",
        "        exp_exp_tradeoff = random.uniform(0, 1)\n",
        "        \n",
        "        if exp_exp_tradeoff > epsilon:\n",
        "            action = np.argmax(qtable[state,:])\n",
        "\n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "            \n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        # update the table\n",
        "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
        "        \n",
        "        total_rewards += reward\n",
        "        \n",
        "        state = new_state\n",
        "        \n",
        "        #if we're dead : finish episode\n",
        "        if done == True: \n",
        "            break\n",
        "        \n",
        "    # Reduce epsilon (because we need less and less exploration)\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
        "    rewards.append(total_rewards)\n",
        "    \n",
        "\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
        "print(qtable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 0.5225\n",
            "[[0.09644137 0.0741405  0.19985092 0.07449617]\n",
            " [0.01066086 0.08292338 0.02025739 0.15208378]\n",
            " [0.17990775 0.02987693 0.04371614 0.04332038]\n",
            " [0.0020905  0.03419568 0.01713777 0.0426111 ]\n",
            " [0.25061562 0.08440413 0.04324309 0.08592872]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.00701813 0.00689937 0.34375864 0.01407261]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.01156982 0.10289315 0.15081127 0.33689173]\n",
            " [0.14082371 0.50368531 0.17084432 0.13095966]\n",
            " [0.70770846 0.06172032 0.00804478 0.05001747]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.15243704 0.33754092 0.57491194 0.00806185]\n",
            " [0.31412203 0.88745135 0.41258074 0.42848649]\n",
            " [0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fogUHWGGSOOq",
        "outputId": "2f43f858-8ddd-43f2-9736-893549b77136"
      },
      "source": [
        "env.reset()\n",
        "\n",
        "for episode in range(5):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "    print(\"EPISODE \", episode)\n",
        "\n",
        "    for step in range(max_steps):\n",
        "      \n",
        "        action = np.argmax(qtable[state,:])        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            env.render()\n",
        "            if new_state == 15:\n",
        "                print(\"WE ARE THE CHAMPIONS\")\n",
        "            else:\n",
        "                print(\"FATALITY\")\n",
        "            \n",
        "            print(\"Number of steps\", step)\n",
        "            \n",
        "            break\n",
        "        state = new_state\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------\n",
            "EPISODE  0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 14\n",
            "--------------------------------------------------------------\n",
            "EPISODE  1\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 18\n",
            "--------------------------------------------------------------\n",
            "EPISODE  2\n",
            "  (Right)\n",
            "SFFF\n",
            "FHF\u001b[41mH\u001b[0m\n",
            "FFFH\n",
            "HFFG\n",
            "FATALITY\n",
            "Number of steps 14\n",
            "--------------------------------------------------------------\n",
            "EPISODE  3\n",
            "  (Right)\n",
            "SFFF\n",
            "FHF\u001b[41mH\u001b[0m\n",
            "FFFH\n",
            "HFFG\n",
            "FATALITY\n",
            "Number of steps 7\n",
            "--------------------------------------------------------------\n",
            "EPISODE  4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "WE ARE THE CHAMPIONS\n",
            "Number of steps 19\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}